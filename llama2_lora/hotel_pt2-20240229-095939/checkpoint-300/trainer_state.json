{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.37453183520599254,
  "eval_steps": 300,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.013946587219834328,
      "learning_rate": 0.01999583853516438,
      "loss": 1.1357,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.03152783587574959,
      "learning_rate": 0.019991677070328756,
      "loss": 1.3057,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.02430560812354088,
      "learning_rate": 0.019987515605493136,
      "loss": 1.5762,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.03687096759676933,
      "learning_rate": 0.01998335414065751,
      "loss": 0.9321,
      "step": 4
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.026205476373434067,
      "learning_rate": 0.019979192675821888,
      "loss": 0.9751,
      "step": 5
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.04537992179393768,
      "learning_rate": 0.019975031210986267,
      "loss": 0.7012,
      "step": 6
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.02319790981709957,
      "learning_rate": 0.019970869746150647,
      "loss": 1.1514,
      "step": 7
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.027198510244488716,
      "learning_rate": 0.019966708281315023,
      "loss": 1.1768,
      "step": 8
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.026688028126955032,
      "learning_rate": 0.019962546816479403,
      "loss": 1.0107,
      "step": 9
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.027742978185415268,
      "learning_rate": 0.01995838535164378,
      "loss": 0.52,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.017290690913796425,
      "learning_rate": 0.019954223886808155,
      "loss": 0.5259,
      "step": 11
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.024143831804394722,
      "learning_rate": 0.019950062421972534,
      "loss": 0.895,
      "step": 12
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.03602828457951546,
      "learning_rate": 0.019945900957136914,
      "loss": 1.042,
      "step": 13
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.03868493810296059,
      "learning_rate": 0.01994173949230129,
      "loss": 0.9253,
      "step": 14
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.019538432359695435,
      "learning_rate": 0.01993757802746567,
      "loss": 0.8286,
      "step": 15
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.028750460594892502,
      "learning_rate": 0.019933416562630046,
      "loss": 0.5039,
      "step": 16
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.022473318502306938,
      "learning_rate": 0.019929255097794422,
      "loss": 0.8252,
      "step": 17
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.01876644417643547,
      "learning_rate": 0.0199250936329588,
      "loss": 0.5903,
      "step": 18
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.029065033420920372,
      "learning_rate": 0.01992093216812318,
      "loss": 0.6187,
      "step": 19
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.014426208101212978,
      "learning_rate": 0.019916770703287557,
      "loss": 0.2732,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.01835629716515541,
      "learning_rate": 0.019912609238451937,
      "loss": 0.5063,
      "step": 21
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.021680880337953568,
      "learning_rate": 0.019908447773616313,
      "loss": 0.5586,
      "step": 22
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.018381770700216293,
      "learning_rate": 0.01990428630878069,
      "loss": 0.4036,
      "step": 23
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0139843188226223,
      "learning_rate": 0.01990012484394507,
      "loss": 0.2484,
      "step": 24
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.022173702716827393,
      "learning_rate": 0.019895963379109448,
      "loss": 0.7319,
      "step": 25
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.019779937341809273,
      "learning_rate": 0.019891801914273824,
      "loss": 0.25,
      "step": 26
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.015408563427627087,
      "learning_rate": 0.019887640449438203,
      "loss": 0.6279,
      "step": 27
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.017980150878429413,
      "learning_rate": 0.01988347898460258,
      "loss": 0.7153,
      "step": 28
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.01553407683968544,
      "learning_rate": 0.019879317519766956,
      "loss": 0.6553,
      "step": 29
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.017622757703065872,
      "learning_rate": 0.019875156054931335,
      "loss": 0.54,
      "step": 30
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.019046414643526077,
      "learning_rate": 0.019870994590095715,
      "loss": 0.7466,
      "step": 31
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.018101511523127556,
      "learning_rate": 0.01986683312526009,
      "loss": 0.6934,
      "step": 32
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.01025469321757555,
      "learning_rate": 0.01986267166042447,
      "loss": 0.5674,
      "step": 33
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.02104567363858223,
      "learning_rate": 0.019858510195588847,
      "loss": 0.8809,
      "step": 34
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.011890831403434277,
      "learning_rate": 0.019854348730753226,
      "loss": 0.2898,
      "step": 35
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.022102177143096924,
      "learning_rate": 0.019850187265917602,
      "loss": 0.48,
      "step": 36
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.014674047939479351,
      "learning_rate": 0.019846025801081982,
      "loss": 0.3022,
      "step": 37
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.019139140844345093,
      "learning_rate": 0.01984186433624636,
      "loss": 0.3066,
      "step": 38
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.016503287479281425,
      "learning_rate": 0.019837702871410737,
      "loss": 0.5918,
      "step": 39
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.019555386155843735,
      "learning_rate": 0.019833541406575114,
      "loss": 0.4966,
      "step": 40
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.015926335006952286,
      "learning_rate": 0.019829379941739493,
      "loss": 0.4143,
      "step": 41
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.016720635816454887,
      "learning_rate": 0.01982521847690387,
      "loss": 0.6763,
      "step": 42
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.010436618700623512,
      "learning_rate": 0.01982105701206825,
      "loss": 0.7246,
      "step": 43
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.016686901450157166,
      "learning_rate": 0.01981689554723263,
      "loss": 0.321,
      "step": 44
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.013563442043960094,
      "learning_rate": 0.019812734082397004,
      "loss": 0.5669,
      "step": 45
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.01583418808877468,
      "learning_rate": 0.019808572617561384,
      "loss": 0.4619,
      "step": 46
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.012616423889994621,
      "learning_rate": 0.01980441115272576,
      "loss": 0.6016,
      "step": 47
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.019653743132948875,
      "learning_rate": 0.019800249687890136,
      "loss": 0.262,
      "step": 48
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.01714310795068741,
      "learning_rate": 0.019796088223054516,
      "loss": 0.4636,
      "step": 49
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.012529288418591022,
      "learning_rate": 0.019791926758218895,
      "loss": 0.0888,
      "step": 50
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.025462329387664795,
      "learning_rate": 0.01978776529338327,
      "loss": 1.1182,
      "step": 51
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.013185207732021809,
      "learning_rate": 0.01978360382854765,
      "loss": 0.6724,
      "step": 52
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.025705890730023384,
      "learning_rate": 0.019779442363712027,
      "loss": 1.2998,
      "step": 53
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.018231689929962158,
      "learning_rate": 0.019775280898876403,
      "loss": 0.4458,
      "step": 54
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.013859216123819351,
      "learning_rate": 0.019771119434040783,
      "loss": 0.623,
      "step": 55
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.020070232450962067,
      "learning_rate": 0.019766957969205162,
      "loss": 0.73,
      "step": 56
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.012890408746898174,
      "learning_rate": 0.01976279650436954,
      "loss": 0.4128,
      "step": 57
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.014063001610338688,
      "learning_rate": 0.019758635039533918,
      "loss": 0.4192,
      "step": 58
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.016345465555787086,
      "learning_rate": 0.019754473574698294,
      "loss": 0.5889,
      "step": 59
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0205059964209795,
      "learning_rate": 0.01975031210986267,
      "loss": 0.4709,
      "step": 60
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.014671096578240395,
      "learning_rate": 0.01974615064502705,
      "loss": 0.3325,
      "step": 61
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.011892193928360939,
      "learning_rate": 0.01974198918019143,
      "loss": 0.4302,
      "step": 62
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.015515914186835289,
      "learning_rate": 0.019737827715355805,
      "loss": 0.9307,
      "step": 63
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.01472906768321991,
      "learning_rate": 0.019733666250520185,
      "loss": 0.3135,
      "step": 64
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.013207866810262203,
      "learning_rate": 0.01972950478568456,
      "loss": 0.4983,
      "step": 65
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.006755692884325981,
      "learning_rate": 0.019725343320848937,
      "loss": 0.4126,
      "step": 66
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.013154924847185612,
      "learning_rate": 0.019721181856013317,
      "loss": 0.5415,
      "step": 67
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.012332231737673283,
      "learning_rate": 0.019717020391177696,
      "loss": 0.5249,
      "step": 68
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.01766934059560299,
      "learning_rate": 0.019712858926342072,
      "loss": 0.4358,
      "step": 69
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.018197795376181602,
      "learning_rate": 0.019708697461506452,
      "loss": 0.6753,
      "step": 70
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.016164090484380722,
      "learning_rate": 0.019704535996670828,
      "loss": 0.4712,
      "step": 71
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.029932130128145218,
      "learning_rate": 0.019700374531835204,
      "loss": 0.5342,
      "step": 72
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.01345884520560503,
      "learning_rate": 0.019696213066999584,
      "loss": 0.5029,
      "step": 73
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.01129131205379963,
      "learning_rate": 0.019692051602163963,
      "loss": 0.5376,
      "step": 74
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.016407852992415428,
      "learning_rate": 0.01968789013732834,
      "loss": 0.791,
      "step": 75
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.019868925213813782,
      "learning_rate": 0.01968372867249272,
      "loss": 0.5015,
      "step": 76
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0146525539457798,
      "learning_rate": 0.019679567207657095,
      "loss": 0.541,
      "step": 77
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.010244067758321762,
      "learning_rate": 0.019675405742821474,
      "loss": 0.2642,
      "step": 78
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.015067693777382374,
      "learning_rate": 0.01967124427798585,
      "loss": 0.2817,
      "step": 79
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.010389878414571285,
      "learning_rate": 0.01966708281315023,
      "loss": 0.6113,
      "step": 80
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.011934892274439335,
      "learning_rate": 0.019662921348314606,
      "loss": 0.0456,
      "step": 81
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.01124374195933342,
      "learning_rate": 0.019658759883478986,
      "loss": 0.2357,
      "step": 82
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.017671743407845497,
      "learning_rate": 0.019654598418643362,
      "loss": 0.5024,
      "step": 83
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.02609691210091114,
      "learning_rate": 0.01965043695380774,
      "loss": 0.5361,
      "step": 84
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.01812068186700344,
      "learning_rate": 0.019646275488972118,
      "loss": 0.4084,
      "step": 85
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.014044742099940777,
      "learning_rate": 0.019642114024136497,
      "loss": 0.2783,
      "step": 86
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.013514760881662369,
      "learning_rate": 0.019637952559300873,
      "loss": 0.5366,
      "step": 87
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.01608353666961193,
      "learning_rate": 0.019633791094465253,
      "loss": 0.4722,
      "step": 88
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.014681047759950161,
      "learning_rate": 0.019629629629629632,
      "loss": 0.3625,
      "step": 89
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.011236661113798618,
      "learning_rate": 0.01962546816479401,
      "loss": 0.2866,
      "step": 90
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.014246581122279167,
      "learning_rate": 0.019621306699958384,
      "loss": 0.4597,
      "step": 91
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.015461236238479614,
      "learning_rate": 0.019617145235122764,
      "loss": 0.251,
      "step": 92
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.013209463097155094,
      "learning_rate": 0.01961298377028714,
      "loss": 0.4397,
      "step": 93
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.017247267067432404,
      "learning_rate": 0.01960882230545152,
      "loss": 0.1571,
      "step": 94
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0060082110576331615,
      "learning_rate": 0.0196046608406159,
      "loss": 0.0955,
      "step": 95
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.04800603538751602,
      "learning_rate": 0.019600499375780275,
      "loss": 0.5498,
      "step": 96
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.010818454436957836,
      "learning_rate": 0.01959633791094465,
      "loss": 0.3552,
      "step": 97
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.013875529170036316,
      "learning_rate": 0.01959217644610903,
      "loss": 0.2754,
      "step": 98
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.009726175107061863,
      "learning_rate": 0.019588014981273407,
      "loss": 0.5693,
      "step": 99
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.010561893694102764,
      "learning_rate": 0.019583853516437787,
      "loss": 0.269,
      "step": 100
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.018042325973510742,
      "learning_rate": 0.019579692051602166,
      "loss": 0.2888,
      "step": 101
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.011434352956712246,
      "learning_rate": 0.019575530586766542,
      "loss": 0.3032,
      "step": 102
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.01294125895947218,
      "learning_rate": 0.01957136912193092,
      "loss": 0.3904,
      "step": 103
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.00973493605852127,
      "learning_rate": 0.019567207657095298,
      "loss": 0.1273,
      "step": 104
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.011769156903028488,
      "learning_rate": 0.019563046192259674,
      "loss": 0.3728,
      "step": 105
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.013946526683866978,
      "learning_rate": 0.019558884727424054,
      "loss": 0.4209,
      "step": 106
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.024769112467765808,
      "learning_rate": 0.019554723262588433,
      "loss": 0.5957,
      "step": 107
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.013953709043562412,
      "learning_rate": 0.01955056179775281,
      "loss": 0.896,
      "step": 108
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.016479069367051125,
      "learning_rate": 0.019546400332917185,
      "loss": 0.2915,
      "step": 109
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.012262118980288506,
      "learning_rate": 0.019542238868081565,
      "loss": 0.3962,
      "step": 110
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.009211440570652485,
      "learning_rate": 0.019538077403245944,
      "loss": 0.2974,
      "step": 111
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.01734967529773712,
      "learning_rate": 0.01953391593841032,
      "loss": 0.583,
      "step": 112
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.02681916393339634,
      "learning_rate": 0.0195297544735747,
      "loss": 0.5518,
      "step": 113
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.019412348046898842,
      "learning_rate": 0.019525593008739076,
      "loss": 0.1301,
      "step": 114
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0728633925318718,
      "learning_rate": 0.019521431543903452,
      "loss": 0.3469,
      "step": 115
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.010789559222757816,
      "learning_rate": 0.019517270079067832,
      "loss": 0.2566,
      "step": 116
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.01410316675901413,
      "learning_rate": 0.01951310861423221,
      "loss": 0.6997,
      "step": 117
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.02386266365647316,
      "learning_rate": 0.019508947149396588,
      "loss": 0.7905,
      "step": 118
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.01500307023525238,
      "learning_rate": 0.019504785684560967,
      "loss": 0.311,
      "step": 119
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.01638227328658104,
      "learning_rate": 0.019500624219725343,
      "loss": 0.377,
      "step": 120
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.018486998975276947,
      "learning_rate": 0.019496462754889723,
      "loss": 0.4883,
      "step": 121
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.004287502728402615,
      "learning_rate": 0.0194923012900541,
      "loss": 0.0809,
      "step": 122
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.012090643867850304,
      "learning_rate": 0.01948813982521848,
      "loss": 0.3147,
      "step": 123
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.012809454463422298,
      "learning_rate": 0.019483978360382855,
      "loss": 0.2346,
      "step": 124
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.03159857168793678,
      "learning_rate": 0.019479816895547234,
      "loss": 0.0633,
      "step": 125
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.03378335013985634,
      "learning_rate": 0.01947565543071161,
      "loss": 0.4414,
      "step": 126
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.00972415879368782,
      "learning_rate": 0.01947149396587599,
      "loss": 0.1332,
      "step": 127
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.014316284097731113,
      "learning_rate": 0.019467332501040366,
      "loss": 0.2642,
      "step": 128
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.01945355348289013,
      "learning_rate": 0.019463171036204745,
      "loss": 0.2568,
      "step": 129
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.014685138128697872,
      "learning_rate": 0.01945900957136912,
      "loss": 0.2495,
      "step": 130
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.010893230326473713,
      "learning_rate": 0.0194548481065335,
      "loss": 0.1844,
      "step": 131
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.015432030893862247,
      "learning_rate": 0.01945068664169788,
      "loss": 0.2192,
      "step": 132
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.023381555452942848,
      "learning_rate": 0.019446525176862257,
      "loss": 0.1019,
      "step": 133
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.025069458410143852,
      "learning_rate": 0.019442363712026633,
      "loss": 0.6982,
      "step": 134
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.013284072279930115,
      "learning_rate": 0.019438202247191012,
      "loss": 0.2725,
      "step": 135
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.01459498330950737,
      "learning_rate": 0.01943404078235539,
      "loss": 0.342,
      "step": 136
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.010649852454662323,
      "learning_rate": 0.019429879317519768,
      "loss": 0.1597,
      "step": 137
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.00572684733197093,
      "learning_rate": 0.019425717852684148,
      "loss": 0.0163,
      "step": 138
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.010500311851501465,
      "learning_rate": 0.019421556387848524,
      "loss": 0.3718,
      "step": 139
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.02403194084763527,
      "learning_rate": 0.0194173949230129,
      "loss": 0.3464,
      "step": 140
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.015808913856744766,
      "learning_rate": 0.01941323345817728,
      "loss": 0.0919,
      "step": 141
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.017955824732780457,
      "learning_rate": 0.019409071993341655,
      "loss": 0.3323,
      "step": 142
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.015312157571315765,
      "learning_rate": 0.019404910528506035,
      "loss": 0.4712,
      "step": 143
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.013958172872662544,
      "learning_rate": 0.019400749063670415,
      "loss": 0.1681,
      "step": 144
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.01720457337796688,
      "learning_rate": 0.01939658759883479,
      "loss": 0.541,
      "step": 145
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.017649512737989426,
      "learning_rate": 0.019392426133999167,
      "loss": 0.6196,
      "step": 146
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.016069641336798668,
      "learning_rate": 0.019388264669163546,
      "loss": 0.3416,
      "step": 147
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.015727760270237923,
      "learning_rate": 0.019384103204327922,
      "loss": 0.2766,
      "step": 148
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.011026602238416672,
      "learning_rate": 0.019379941739492302,
      "loss": 0.2603,
      "step": 149
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.011536615900695324,
      "learning_rate": 0.01937578027465668,
      "loss": 0.0615,
      "step": 150
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.018519138917326927,
      "learning_rate": 0.019371618809821058,
      "loss": 0.2013,
      "step": 151
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.019297972321510315,
      "learning_rate": 0.019367457344985434,
      "loss": 0.7739,
      "step": 152
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.035224251449108124,
      "learning_rate": 0.019363295880149813,
      "loss": 0.1853,
      "step": 153
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.011118430644273758,
      "learning_rate": 0.01935913441531419,
      "loss": 0.585,
      "step": 154
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.01876828819513321,
      "learning_rate": 0.01935497295047857,
      "loss": 0.439,
      "step": 155
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.013631806708872318,
      "learning_rate": 0.01935081148564295,
      "loss": 0.2147,
      "step": 156
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.013377000577747822,
      "learning_rate": 0.019346650020807325,
      "loss": 0.0768,
      "step": 157
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.009209630079567432,
      "learning_rate": 0.0193424885559717,
      "loss": 0.12,
      "step": 158
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.010687937960028648,
      "learning_rate": 0.01933832709113608,
      "loss": 0.3562,
      "step": 159
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.01562159787863493,
      "learning_rate": 0.019334165626300456,
      "loss": 0.2192,
      "step": 160
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.005969279445707798,
      "learning_rate": 0.019330004161464836,
      "loss": 0.0499,
      "step": 161
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.01860101707279682,
      "learning_rate": 0.019325842696629215,
      "loss": 0.4082,
      "step": 162
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.013926600106060505,
      "learning_rate": 0.01932168123179359,
      "loss": 0.27,
      "step": 163
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.007220026105642319,
      "learning_rate": 0.01931751976695797,
      "loss": 0.139,
      "step": 164
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.016826435923576355,
      "learning_rate": 0.019313358302122347,
      "loss": 0.4153,
      "step": 165
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.008984547108411789,
      "learning_rate": 0.019309196837286723,
      "loss": 0.2205,
      "step": 166
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.014899051748216152,
      "learning_rate": 0.019305035372451103,
      "loss": 0.4397,
      "step": 167
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.008856400847434998,
      "learning_rate": 0.019300873907615482,
      "loss": 0.0795,
      "step": 168
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.015470389276742935,
      "learning_rate": 0.01929671244277986,
      "loss": 0.6055,
      "step": 169
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.01177644170820713,
      "learning_rate": 0.019292550977944238,
      "loss": 0.3594,
      "step": 170
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.018051499500870705,
      "learning_rate": 0.019288389513108614,
      "loss": 0.7207,
      "step": 171
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.01194706466048956,
      "learning_rate": 0.01928422804827299,
      "loss": 0.4624,
      "step": 172
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.021377161145210266,
      "learning_rate": 0.01928006658343737,
      "loss": 0.4302,
      "step": 173
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.011635289527475834,
      "learning_rate": 0.01927590511860175,
      "loss": 0.2068,
      "step": 174
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.012977547012269497,
      "learning_rate": 0.019271743653766125,
      "loss": 0.3076,
      "step": 175
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.011483551934361458,
      "learning_rate": 0.019267582188930505,
      "loss": 0.2173,
      "step": 176
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.018402379006147385,
      "learning_rate": 0.01926342072409488,
      "loss": 0.3831,
      "step": 177
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.008669276721775532,
      "learning_rate": 0.019259259259259257,
      "loss": 0.1942,
      "step": 178
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.009989948943257332,
      "learning_rate": 0.019255097794423637,
      "loss": 0.4062,
      "step": 179
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.007285960018634796,
      "learning_rate": 0.019250936329588016,
      "loss": 0.0542,
      "step": 180
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.022931115701794624,
      "learning_rate": 0.019246774864752392,
      "loss": 0.3311,
      "step": 181
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.015280869789421558,
      "learning_rate": 0.019242613399916772,
      "loss": 0.1851,
      "step": 182
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.016446208581328392,
      "learning_rate": 0.019238451935081148,
      "loss": 0.3059,
      "step": 183
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.009221578016877174,
      "learning_rate": 0.019234290470245528,
      "loss": 0.1036,
      "step": 184
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.01323636807501316,
      "learning_rate": 0.019230129005409904,
      "loss": 0.3828,
      "step": 185
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.011723767034709454,
      "learning_rate": 0.019225967540574283,
      "loss": 0.6211,
      "step": 186
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.00718157272785902,
      "learning_rate": 0.019221806075738663,
      "loss": 0.1534,
      "step": 187
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.009665646590292454,
      "learning_rate": 0.01921764461090304,
      "loss": 0.1459,
      "step": 188
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.01421988382935524,
      "learning_rate": 0.019213483146067415,
      "loss": 0.3362,
      "step": 189
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.014052601531147957,
      "learning_rate": 0.019209321681231795,
      "loss": 0.4727,
      "step": 190
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.007880319841206074,
      "learning_rate": 0.01920516021639617,
      "loss": 0.0958,
      "step": 191
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.013098879717290401,
      "learning_rate": 0.01920099875156055,
      "loss": 0.2483,
      "step": 192
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.010881153866648674,
      "learning_rate": 0.01919683728672493,
      "loss": 0.0822,
      "step": 193
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.011607570573687553,
      "learning_rate": 0.019192675821889306,
      "loss": 0.4939,
      "step": 194
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.015284847468137741,
      "learning_rate": 0.019188514357053682,
      "loss": 0.4248,
      "step": 195
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.006532551255077124,
      "learning_rate": 0.01918435289221806,
      "loss": 0.0183,
      "step": 196
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.00698343338444829,
      "learning_rate": 0.019180191427382438,
      "loss": 0.0674,
      "step": 197
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.01601043902337551,
      "learning_rate": 0.019176029962546817,
      "loss": 1.0,
      "step": 198
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.018778465688228607,
      "learning_rate": 0.019171868497711197,
      "loss": 0.5615,
      "step": 199
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.017414990812540054,
      "learning_rate": 0.019167707032875573,
      "loss": 0.4424,
      "step": 200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.009499352425336838,
      "learning_rate": 0.01916354556803995,
      "loss": 0.0865,
      "step": 201
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.011209850199520588,
      "learning_rate": 0.01915938410320433,
      "loss": 0.3103,
      "step": 202
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.011232535354793072,
      "learning_rate": 0.019155222638368705,
      "loss": 0.3169,
      "step": 203
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.016806548461318016,
      "learning_rate": 0.019151061173533084,
      "loss": 0.6245,
      "step": 204
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.01189274899661541,
      "learning_rate": 0.019146899708697464,
      "loss": 0.1663,
      "step": 205
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.015232094563543797,
      "learning_rate": 0.01914273824386184,
      "loss": 0.6851,
      "step": 206
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.02008361555635929,
      "learning_rate": 0.01913857677902622,
      "loss": 0.4065,
      "step": 207
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.007860634475946426,
      "learning_rate": 0.019134415314190596,
      "loss": 0.114,
      "step": 208
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.009345010854303837,
      "learning_rate": 0.01913025384935497,
      "loss": 0.3083,
      "step": 209
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.01482164952903986,
      "learning_rate": 0.01912609238451935,
      "loss": 0.5288,
      "step": 210
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.013445671647787094,
      "learning_rate": 0.01912193091968373,
      "loss": 0.0577,
      "step": 211
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.01909550465643406,
      "learning_rate": 0.019117769454848107,
      "loss": 0.3801,
      "step": 212
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.013162663206458092,
      "learning_rate": 0.019113607990012486,
      "loss": 0.2639,
      "step": 213
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.01083003357052803,
      "learning_rate": 0.019109446525176862,
      "loss": 0.1499,
      "step": 214
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.00959020759910345,
      "learning_rate": 0.01910528506034124,
      "loss": 0.1101,
      "step": 215
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.010005058720707893,
      "learning_rate": 0.019101123595505618,
      "loss": 0.2026,
      "step": 216
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.02039876952767372,
      "learning_rate": 0.019096962130669998,
      "loss": 0.282,
      "step": 217
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.014765151776373386,
      "learning_rate": 0.019092800665834374,
      "loss": 0.3125,
      "step": 218
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.009571024216711521,
      "learning_rate": 0.019088639200998753,
      "loss": 0.183,
      "step": 219
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.010038415901362896,
      "learning_rate": 0.01908447773616313,
      "loss": 0.1028,
      "step": 220
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.012818839401006699,
      "learning_rate": 0.019080316271327506,
      "loss": 0.5225,
      "step": 221
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.014451993629336357,
      "learning_rate": 0.019076154806491885,
      "loss": 0.168,
      "step": 222
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.006471678148955107,
      "learning_rate": 0.019071993341656265,
      "loss": 0.0197,
      "step": 223
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.004482632502913475,
      "learning_rate": 0.01906783187682064,
      "loss": 0.0293,
      "step": 224
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.016593338921666145,
      "learning_rate": 0.01906367041198502,
      "loss": 0.5806,
      "step": 225
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.00906510278582573,
      "learning_rate": 0.019059508947149396,
      "loss": 0.1466,
      "step": 226
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.010454477742314339,
      "learning_rate": 0.019055347482313773,
      "loss": 0.1746,
      "step": 227
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0206717811524868,
      "learning_rate": 0.019051186017478152,
      "loss": 0.6543,
      "step": 228
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.009957603178918362,
      "learning_rate": 0.01904702455264253,
      "loss": 0.0541,
      "step": 229
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.02599034458398819,
      "learning_rate": 0.019042863087806908,
      "loss": 0.4255,
      "step": 230
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.017418760806322098,
      "learning_rate": 0.019038701622971287,
      "loss": 0.4253,
      "step": 231
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.013599650003015995,
      "learning_rate": 0.019034540158135663,
      "loss": 0.3621,
      "step": 232
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.012645847164094448,
      "learning_rate": 0.01903037869330004,
      "loss": 0.1808,
      "step": 233
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.011502467095851898,
      "learning_rate": 0.01902621722846442,
      "loss": 0.4675,
      "step": 234
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.009859512560069561,
      "learning_rate": 0.0190220557636288,
      "loss": 0.0282,
      "step": 235
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.009849142283201218,
      "learning_rate": 0.019017894298793175,
      "loss": 0.0837,
      "step": 236
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.015944460406899452,
      "learning_rate": 0.019013732833957554,
      "loss": 0.2374,
      "step": 237
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.015828672796487808,
      "learning_rate": 0.01900957136912193,
      "loss": 0.5649,
      "step": 238
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.011765114963054657,
      "learning_rate": 0.01900540990428631,
      "loss": 0.4055,
      "step": 239
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.012066415511071682,
      "learning_rate": 0.019001248439450686,
      "loss": 0.3311,
      "step": 240
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.01208413578569889,
      "learning_rate": 0.018997086974615066,
      "loss": 0.3303,
      "step": 241
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.020172521471977234,
      "learning_rate": 0.01899292550977944,
      "loss": 0.6533,
      "step": 242
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.013071781024336815,
      "learning_rate": 0.01898876404494382,
      "loss": 0.2922,
      "step": 243
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.014257648959755898,
      "learning_rate": 0.018984602580108197,
      "loss": 0.5166,
      "step": 244
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.008450665511190891,
      "learning_rate": 0.018980441115272577,
      "loss": 0.1483,
      "step": 245
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.01024819165468216,
      "learning_rate": 0.018976279650436953,
      "loss": 0.3325,
      "step": 246
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.012138486839830875,
      "learning_rate": 0.018972118185601333,
      "loss": 0.3181,
      "step": 247
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.01706678234040737,
      "learning_rate": 0.01896795672076571,
      "loss": 0.5381,
      "step": 248
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.0165503341704607,
      "learning_rate": 0.018963795255930088,
      "loss": 0.3474,
      "step": 249
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.017817780375480652,
      "learning_rate": 0.018959633791094468,
      "loss": 0.1743,
      "step": 250
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.01351422630250454,
      "learning_rate": 0.018955472326258844,
      "loss": 0.1572,
      "step": 251
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.01826195791363716,
      "learning_rate": 0.01895131086142322,
      "loss": 0.3682,
      "step": 252
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.01721639558672905,
      "learning_rate": 0.0189471493965876,
      "loss": 0.4712,
      "step": 253
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0058861286379396915,
      "learning_rate": 0.018942987931751976,
      "loss": 0.0426,
      "step": 254
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0133828679099679,
      "learning_rate": 0.018938826466916355,
      "loss": 0.3984,
      "step": 255
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.015871714800596237,
      "learning_rate": 0.018934665002080735,
      "loss": 0.4358,
      "step": 256
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.012308573350310326,
      "learning_rate": 0.01893050353724511,
      "loss": 0.303,
      "step": 257
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.010923982597887516,
      "learning_rate": 0.018926342072409487,
      "loss": 0.1774,
      "step": 258
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.013635121285915375,
      "learning_rate": 0.018922180607573866,
      "loss": 0.4199,
      "step": 259
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.013736642897129059,
      "learning_rate": 0.018918019142738246,
      "loss": 0.3162,
      "step": 260
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.018210401758551598,
      "learning_rate": 0.018913857677902622,
      "loss": 0.3315,
      "step": 261
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.01903851330280304,
      "learning_rate": 0.018909696213067,
      "loss": 0.6294,
      "step": 262
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.01758592203259468,
      "learning_rate": 0.018905534748231378,
      "loss": 0.853,
      "step": 263
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.014722253195941448,
      "learning_rate": 0.018901373283395754,
      "loss": 0.2148,
      "step": 264
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.010228004306554794,
      "learning_rate": 0.018897211818560133,
      "loss": 0.07,
      "step": 265
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.017041178420186043,
      "learning_rate": 0.018893050353724513,
      "loss": 0.3865,
      "step": 266
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.024548158049583435,
      "learning_rate": 0.01888888888888889,
      "loss": 0.408,
      "step": 267
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.021002428606152534,
      "learning_rate": 0.01888472742405327,
      "loss": 0.4521,
      "step": 268
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.023030998185276985,
      "learning_rate": 0.018880565959217645,
      "loss": 0.6274,
      "step": 269
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.01349740382283926,
      "learning_rate": 0.01887640449438202,
      "loss": 0.3054,
      "step": 270
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.01190619170665741,
      "learning_rate": 0.0188722430295464,
      "loss": 0.1816,
      "step": 271
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.01658334955573082,
      "learning_rate": 0.01886808156471078,
      "loss": 0.491,
      "step": 272
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.008173597976565361,
      "learning_rate": 0.018863920099875156,
      "loss": 0.0178,
      "step": 273
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.017877396196126938,
      "learning_rate": 0.018859758635039536,
      "loss": 0.4114,
      "step": 274
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.012737761251628399,
      "learning_rate": 0.01885559717020391,
      "loss": 0.2288,
      "step": 275
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.02273883856832981,
      "learning_rate": 0.018851435705368288,
      "loss": 0.4519,
      "step": 276
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.006959815509617329,
      "learning_rate": 0.018847274240532667,
      "loss": 0.0447,
      "step": 277
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.012611573562026024,
      "learning_rate": 0.018843112775697047,
      "loss": 0.1226,
      "step": 278
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.014003496617078781,
      "learning_rate": 0.018838951310861423,
      "loss": 0.4014,
      "step": 279
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.01877623423933983,
      "learning_rate": 0.018834789846025803,
      "loss": 0.2646,
      "step": 280
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.018713688477873802,
      "learning_rate": 0.01883062838119018,
      "loss": 0.5034,
      "step": 281
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.02422862872481346,
      "learning_rate": 0.018826466916354558,
      "loss": 0.8271,
      "step": 282
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.016888445243239403,
      "learning_rate": 0.018822305451518934,
      "loss": 0.541,
      "step": 283
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.025673290714621544,
      "learning_rate": 0.018818143986683314,
      "loss": 0.5269,
      "step": 284
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.013471826910972595,
      "learning_rate": 0.01881398252184769,
      "loss": 0.1483,
      "step": 285
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.016805335879325867,
      "learning_rate": 0.01880982105701207,
      "loss": 0.4895,
      "step": 286
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.02230897918343544,
      "learning_rate": 0.018805659592176446,
      "loss": 0.2627,
      "step": 287
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.017700405791401863,
      "learning_rate": 0.018801498127340825,
      "loss": 0.2869,
      "step": 288
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.026683760806918144,
      "learning_rate": 0.0187973366625052,
      "loss": 0.4714,
      "step": 289
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.017930233851075172,
      "learning_rate": 0.01879317519766958,
      "loss": 0.124,
      "step": 290
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.014429387636482716,
      "learning_rate": 0.018789013732833957,
      "loss": 0.4141,
      "step": 291
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.012393507175147533,
      "learning_rate": 0.018784852267998337,
      "loss": 0.1812,
      "step": 292
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.013746536336839199,
      "learning_rate": 0.018780690803162716,
      "loss": 0.2296,
      "step": 293
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.017592409625649452,
      "learning_rate": 0.018776529338327092,
      "loss": 0.4626,
      "step": 294
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.02273542992770672,
      "learning_rate": 0.01877236787349147,
      "loss": 0.2491,
      "step": 295
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.04013910889625549,
      "learning_rate": 0.018768206408655848,
      "loss": 0.5811,
      "step": 296
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.012396056205034256,
      "learning_rate": 0.018764044943820224,
      "loss": 0.5254,
      "step": 297
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.01785169169306755,
      "learning_rate": 0.018759883478984603,
      "loss": 0.397,
      "step": 298
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.01874547079205513,
      "learning_rate": 0.018755722014148983,
      "loss": 0.2937,
      "step": 299
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.01092853955924511,
      "learning_rate": 0.01875156054931336,
      "loss": 0.4192,
      "step": 300
    },
    {
      "epoch": 0.37,
      "eval_loss": 0.3251953125,
      "eval_runtime": 183.3307,
      "eval_samples_per_second": 1.096,
      "eval_steps_per_second": 0.551,
      "step": 300
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 4806,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 300,
  "total_flos": 3.45389723025408e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
