{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea52af6-dabe-4826-9a3c-84e8244895ee",
   "metadata": {},
   "source": [
    "# Llama2-7B-Chat大模型的LoRA微调\n",
    "\n",
    "Llama2系列是Meta开发并公开的大型语言模型（LLMs），有7B、13B和70B三种不同参数大小的模型，每种参数大小分别对应一个预训练和一个微调的版本。\n",
    "\n",
    "微调版本称为Llama2-Chat，使用了和 ChatGPT 相似的技术，针对对话进行了优化。相比于 Llama1，Llama2的训练数据多了 40%，上下文长度翻倍，并采用了分组查询注意力机制。特别地，Llama2的预训练模型在2万亿的token 上训练，精调的Llama2-Chat模型在100万人类标记数据上进行进一步训练得到。Llama-2-Chat模型在Meta多数基准上优于开源聊天模型，并且在Meta和安全性的人类评估中，与一些流行的闭源模型如ChatGPT和PaLM相当。\n",
    "\n",
    "Llama2-7B-Chat是具有70亿参数的微调模型，本文将以Llama2-7B-Chat为例，为您介绍如何在PAI-DSW中使用单卡对Llama2大模型进行轻量化LoRA微调及量化。\n",
    "\n",
    "\n",
    "### 注意：使用此模型受Meta许可证的约束。在使用模型前，请确认已经前往[自定义可商用开源协议](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)网站并完成申请。\n",
    "\n",
    "## 运行环境要求\n",
    "\n",
    "Python环境3.9以上，GPU推荐使用T4、A10或者V100（16GB）及以上配置。\n",
    "\n",
    "\n",
    "## 准备工作\n",
    "\n",
    "### 下载Llama2-7B-Chat\n",
    "\n",
    "首先，下载模型文件。\n",
    "\n",
    "您可以选择直接执行下面脚本下载，也可以选择[从ModelScope下载模型](https://modelscope.cn/models/modelscope/Llama-2-7b-chat-ms/summary)。\n",
    "运行如下代码，会根据当前地域为您选择合适的下载地址，并将模型下载到当前目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbfbc4-c5c7-43c4-8c7c-800f671d73bb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dsw_region = os.environ.get(\"dsw_region\")\n",
    "url_link = {\n",
    "    \"cn-shanghai\": \"https://atp-modelzoo-sh.oss-cn-shanghai-internal.aliyuncs.com/release/tutorials/llama2/llama2-7b.tar.gz\",\n",
    "    \"cn-hangzhou\": \"https://atp-modelzoo.oss-cn-hangzhou-internal.aliyuncs.com/release/tutorials/llama2/llama2-7b.tar.gz\",\n",
    "    \"cn-shenzhen\": \"https://atp-modelzoo-sz.oss-cn-shenzhen-internal.aliyuncs.com/release/tutorials/llama2/llama2-7b.tar.gz\",\n",
    "    \"cn-beijing\": \"https://atp-modelzoo-bj.oss-cn-beijing-internal.aliyuncs.com/release/tutorials/llama2/llama2-7b.tar.gz\", \n",
    "}\n",
    "\n",
    "path = url_link[dsw_region] if dsw_region in url_link else \"https://atp-modelzoo.oss-cn-hangzhou.aliyuncs.com/release/tutorials/llama2/llama2-7b.tar.gz\"\n",
    "os.environ['LINK_CHAT'] = path\n",
    "!wget $LINK_CHAT\n",
    "!tar -zxvf llama2-7b.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa93626-6648-4e41-8348-bd3a54d96f17",
   "metadata": {},
   "source": [
    "### 下载和安装环境\n",
    "\n",
    "接着下载和安装所需要的环境。\n",
    "\n",
    "* `llama-recipes`是Meta官方发布的快速微调Llama2的开源库。\n",
    "* `PEFT`（Parameter-Efficient Fine-Tuning，参数高效微调）是Hugging Face开源的大模型轻量化微调工具。\n",
    "* `gradio`是一个快速构建机器学习Web展示页面的开源库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b73bcf-7938-49a6-9f19-570eb62313b0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/tutorials/llama2/llama-recipes.tar.gz\n",
    "! tar -zxvf llama-recipes.tar.gz\n",
    "! wget https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/tutorials/llama2/peft.tar.gz\n",
    "! tar -zxvf peft.tar.gz\n",
    "! pip install -r llama-recipes/requirements.txt\n",
    "! pip install peft\n",
    "! pip install gradio==3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e4577a-99c4-4c42-ba96-d3c84b7f34d6",
   "metadata": {},
   "source": [
    "### 自定义训练数据（可选）\n",
    "\n",
    "我们已经准备好了示例数据集，在`llama-recipes/ft_datasets/alpaca_data_sub.json`。为了方便起见，您可以跳过本步，直接用这个数据集进行finetune。\n",
    "\n",
    "如果您希望使用自定义数据集，请阅读以下步骤。\n",
    "\n",
    "首先在`llama-recipes/ft_datasets/`目录下新建一个json文件（如`your_dataset.json`），数据格式示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c47eb-de3c-430e-b7f2-4668c84f8d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[\n",
    "    {\n",
    "        \"instruction\": \"Give three tips for staying healthy.\",\n",
    "        \"output\": \"1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"What are the three primary colors?\",\n",
    "        \"output\": \"The three primary colors are red, blue, and yellow.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c5155-4d87-4649-9982-b65fe1cd5417",
   "metadata": {
    "tags": []
   },
   "source": [
    "准备好训练数据后，请您在`llama-recipes/configs/training.py`文件中修改`alpaca_dataset`类的参数，将`data_path`改为您创建的json文件，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a2930-297c-49ea-a094-2e9a3ebf5480",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class alpaca_dataset:\n",
    "    dataset: str = \"alpaca_dataset\"\n",
    "    train_split: str = \"train\"\n",
    "    test_split: str = \"val\"\n",
    "    # 修改这里的data_path\n",
    "    data_path: str = \"llama-recipes/ft_datasets/your_dataset.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac4337-b324-4eda-804f-fbb6036802f8",
   "metadata": {},
   "source": [
    "这样您的数据集便配置完成。如果您需要更灵活的配置，请参考`llama-recipes/docs/Dataset.md`的指导。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375621a8-b3e0-47fe-9896-a4f9c0ddcc3f",
   "metadata": {},
   "source": [
    "## LoRA微调及量化\n",
    "\n",
    "您可以使用已经写好的训练脚本，进行模型的LoRA轻量化训练。在训练结束之后，我们将模型参数进行int8量化，以便使用更少显存进行推理。\n",
    "\n",
    "示例使用的参数解释如下，请您根据实际情况进行修改：\n",
    "\n",
    "`--num_epochs 3`：finetune 3代 \n",
    "\n",
    "`--use_peft`: 使用PEFT\n",
    "\n",
    "`--peft_method lora`：有三种可选的方法，`lora`, `llama_adapter`和`prefix`，这里采用了`lora`\n",
    "\n",
    "`--quantization`: 采用int8量化\n",
    "\n",
    "`--dataset alpaca_dataset`: 采用alpaca数据集\n",
    "\n",
    "`--model_name llama2-7b`: 模型为llama2-7b\n",
    "\n",
    "`--output_dir sft-llama2-7b`: 模型的输出目录为`sft-llama2-7b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50bc36-ddaa-4b6a-9670-b2c4bf3c85ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python llama-recipes/llama_finetuning.py --num_epochs 3 --use_peft --peft_method lora --quantization --dataset alpaca_dataset --model_name llama2-7b --output_dir sft-llama2-7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e8f1eb-a10c-4664-a9b9-3a282ad87a4f",
   "metadata": {},
   "source": [
    "## 试玩模型\n",
    "\n",
    "模型训练完成后，运行`llama-recipes/inference/webui.py`文件，试玩微调完成的模型。\n",
    "\n",
    "注意这句代码中的模型地址需要跟上文设置的输出路径保持一致： `model = load_peft_model(model, 'sft-llama2-7b')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a9651-1940-4d16-8e1e-32c18aee504c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python llama-recipes/inference/webui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6cc4f-e198-4d7a-9ac4-f7a0de08d466",
   "metadata": {},
   "source": [
    "运行成功后打开链接，就可以看到如下界面了。请发挥你的创意，与Llama2对话助手互动吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f45d2-d7ba-4081-b39c-f99fc68232ac",
   "metadata": {},
   "source": [
    "![image.png](_html/web_ui_result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ec829-ef7f-4512-89f8-428b689b6785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dsw_sample": {
   "buildId": "716",
   "pipeline": "pai-dsw-examples-master"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
